<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="DESCRIPTION META TAG">
  <meta property="og:title" content="SOCIAL MEDIA TITLE TAG"/>
  <meta property="og:description" content="SOCIAL MEDIA DESCRIPTION TAG TAG"/>
  <meta property="og:url" content="URL OF THE WEBSITE"/>
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->


  <title>GAMap</title>
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>
<body>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">GAMap: Zero-Shot Object Goal Navigation with Multi-Scale Geometric-Affordance Guidance</h1>
            <div class="is-size-5 publication-authors">
              <!-- Paper authors -->
              <span class="author-block">
                <a>Shuaihang Yuan</a>,</span>
                <span class="author-block">
                  <a>Hao Huang</a>,</span>
                  <span class="author-block">
                    <a>Yu Hao</a>,</span>
                    <span class="author-block">
                      <a>Congcong Wen</a>,</span>
                      <span class="author-block">
                        <a>Anthony Tzes</a>,</span>
                        <span class="author-block">
                          <a>Yi Fang</a>
                  </span>
                  </div>

                  <div class="is-size-5 publication-authors">
                    <span class="author-block">NYUAD Center for Artificial Intelligence and Robotics (CAIR)<br>
                      New York University Abu Dhabi, Electrical Engineering<br>
                      New York University, Electrical & Computer Engineering Dept<br>
                      Embodied AI and Robotics (AIR) Lab<br>NeurIPS 2024</span>
                  </div>

                  <div class="column has-text-centered">
                    <div class="publication-links">
                         <!-- Arxiv PDF link -->
                      <span class="link-block">
                        <a href="https://nips.cc/virtual/2024/poster/95755" target="_blank"
                        class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                          <i class="fas fa-file-pdf"></i>
                        </span>
                        <span>Paper</span>
                      </a>
                    </span>


                  <!-- Github link -->
                  <span class="link-block">
                    <a href="https://github.com/shalexyuan/GAMap/tree/main" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>

                <!-- ArXiv abstract Link -->
                <span class="link-block">
                  <a href="https://arxiv.org/pdf/2410.23978" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<!-- Teaser video-->
<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <!-- Replacing video with a pipeline figure image -->
      <img src="static/images/nips24_pipeline.png" alt="Pipeline Figure" width="100%">
      <h2 class="subtitle has-text-centered">
        Pipeline of the GAMap generation.
      </h2>
    </div>
  </div>
</section>
<!-- End teaser video -->

<!-- Paper abstract -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Zero-Shot Object Goal Navigation (ZS-OGN) enables robots to navigate toward
            objects of unseen categories without prior training. Traditional approaches often
            leverage categorical semantic information for navigation guidance, which struggles
            when only partial objects are observed or detailed and functional representations
            of the environment are lacking. To resolve the above two issues, we propose
            Geometric-part and Affordance Maps (GAMap), a novel method that integrates
            object parts and affordance attributes for navigation guidance. Our method includes
            a multi-scale scoring approach to capture geometric-part and affordance attributes
            of objects at different scales. Comprehensive experiments conducted on the HM3D
            and Gibson benchmark datasets demonstrate improvements in Success Rates and
            Success weighted by Path Length, underscoring the efficacy of our geometric-part
            and affordance-guided navigation approach in enhancing robot autonomy and
            versatility, without any additional task-specific training or fine-tuning with the
            semantics of unseen objects and/or the locomotions of the robot.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->


<section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container">
      <!-- Results Figure Presentation. -->
      <h2 class="title is-3">Results</h2>
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <div class="figure-display">
            <!-- Single Large Figure -->
            <img src="static/images/nips_result1.png" alt="Result Figure 1" style="width:100%;">
          </div>
        </div>
      </div>
    </div>
  </div>
    <!-- YouTube Video Presentation -->

</section>

<section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container">
      <!-- Paper video. -->
      <h2 class="title is-3">Real-World Video</h2>
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          
          <div class="publication-video">
            <!-- Youtube embed code here -->
            <iframe src="https://www.youtube.com/embed/QYLM2XtZCK8?si=XVZckXBvLuLqq9bR" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<!--BibTex citation -->
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code></code></pre>
    </div>
</section>
<!--End BibTex citation -->


  <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">

          <p>
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> which was adopted from the <a href="https://nerfies.github.io" target="_blank">Nerfies</a> project page.
            You are free to borrow the source code of this website, we just ask that you link back to this page in the footer. <br> This website is licensed under a <a rel="license"  href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>

        </div>
      </div>
    </div>
  </div>
</footer>

<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

  </body>
  </html>
